{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn的安装\n",
    "- pip install -U scikit-learn\n",
    "- 前提是要安装好numpy、scipy\n",
    "\n",
    "安装很顺利，但是导入包时报错如下\n",
    "> 错误提示：numpy、scipy版本不能太旧，有可能和最新的Sklearn包不兼容，导致报错\n",
    "> \n",
    ">如import sklearn报错\n",
    ">\n",
    ">RuntimeError: module compiled against API version 0xc but this version of numpy is 0xb\n",
    ">\n",
    "如from sklearn.databasets import * 报错\n",
    ">\n",
    "ImportError: cannot import name murmurhash3_32\n",
    "\n",
    "解决方法：我更新了numpy版本，以上问题解决了\n",
    ">numpy version：1.15.0\n",
    ">\n",
    "scipy Version: 1.1.0\n",
    ">\n",
    "scikit-learn Version: 0.19.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn 包含了很多种机器学习的方式:\n",
    "\n",
    "- Classification 分类\n",
    "- Regression 回归\n",
    "- Clustering 非监督分类\n",
    "- Dimensionality reduction 数据降维\n",
    "- Model Selection 模型选择\n",
    "- Preprocessing 数据预处理\n",
    "\n",
    "#### Sklearn的datasets模块的数据集\n",
    "- load_boston()、fetch_california_housing()：回归\n",
    "- load_digits()、load_wine()：分类\n",
    "- load_iris()、load_breast_cancer()：分类、聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载后的数据集可视为一个字典，基本都有data（数据）、target（标签）、feature_names（特征名）、DESCR（描述信息）键**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data = cancer['data']\n",
    "cancer_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_name = cancer['feature_names']\n",
    "cancer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_target = cancer['target']\n",
    "cancer_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集划分\n",
    "- 训练集 train：用于估计模型\n",
    "- 验证集 validation：确定网络结构或控制模型复杂程度的参数（不懂）\n",
    "- 测试集test：检验最优模型性能\n",
    "\n",
    "数据量大时，典型划分方式各占 0.5,0.25,0.25\n",
    "\n",
    "有一种**K折交叉验证法**\n",
    "> from sklearn.model_selection import KFold\n",
    "\n",
    "- 使用model_seelection模块的train_test_split()方法\n",
    "> 有时会看到有cross_validation的使用，但**cross_validation模块在0.18版本中被弃用，现在已经被model_selection代替**。所以在导入的时候把\"sklearn.cross_validation import  train_test_split \"更改为  \"from sklearn.model_selection import  train_test_split\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split函数参数\n",
    "- *arrays：接收一个或多个待划分的数据集\n",
    "    - 分类、回归，则分别传入data、target数据集\n",
    "    - 聚类，则传入data数据集\n",
    "    \n",
    "- test_size：代表测试集大小\n",
    "    - 传入float（0~1）表示占比\n",
    "    - 传入int表示测试集记录的绝对数目\n",
    "    - test_size、train_size都默认25%\n",
    "- train_size：训练集大小，同上\n",
    "- random_state：接收int，随机种子编号，不同随机种子编号产生不同随机结果\n",
    "- shuffle：接收bool型，是否有放回抽样，True表示有放回抽样，此时stratify不能为空\n",
    "- stratify：接收array/None。若为array，使用传入的标签进行分层抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "cancer_data_train,cancer_data_test,cancer_target_train,cancer_target_test = train_test_split(cancer_data,cancer_target,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用转换器进行数据预处理、降维\n",
    "数据预处理模块**preprocessing**\n",
    "其中部分处理函数（标准化、归一化、二值化）：\n",
    "- MinMaxScaler()：离差标准化\n",
    "- StandardScaler()：特征标准差标准化\n",
    "- Normalizer()：特征归一化\n",
    "- Binarizer()：定量特征二值化\n",
    "- OneHotEncoder()：定性特征独热编码处理\n",
    "- FunctionTransformer()：特征自定义函数变换\n",
    "\n",
    "> 降维是什么鬼？\n",
    "> 处理一组高维数据(n*m维向量)，当n、m都非常大时，处理非常难，为了更快地处理数据采取降低数据的维度m\n",
    "\n",
    "PCA降维（主成分分析）：提取数据的主要特征分量\n",
    "\n",
    "`from sklearn.decomposition import PCA`\n",
    "常用参数：\n",
    "- n_components：None，所有特征都会保留；int，原始数据会降维到n个维度；float，会根据样本特征方差来决定降维后维度数；\"mle\"，会根据MLE算法依特征的方差分布情况自动选择一定数量的主成分特征来降维\n",
    "- copy=False：运行算法时，是否将原数据复制一份。True，运行后原始数据不会变\n",
    "- whiten=False：是否白化，即对降维后的数据的每个特征进行归一化，让方差都为1\n",
    "- svd_solver=\"auto\"：代表使用的SVD算法\n",
    "    - full\n",
    "    - arpack\n",
    "    - randomized\n",
    "    - auto：自动权衡选择以上三种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2512257517694716"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "##通过训练集生成离差标准化规则\n",
    "scaler = MinMaxScaler().fit(cancer_data_train)\n",
    "##将规则分别运用于训练集、测试集\n",
    "cancer_train_scaler = scaler.transform(cancer_data_train)\n",
    "cancer_test_scaler = scaler.transform(cancer_data_test)\n",
    "# cancer_test_scaler.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "降维前  (455, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(455, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##PCA降维规则\n",
    "pca_model = PCA(n_components=15).fit(cancer_train_scaler)\n",
    "##规则分别应用于训练集、测试集\n",
    "cancer_train_pca = pca_model.transform(cancer_train_scaler)\n",
    "cancer_test_pca = pca_model.transform(cancer_test_scaler)\n",
    "print('降维前 ',cancer_train_scaler.shape)\n",
    "cancer_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35554047,  0.42156407, -0.04121754, -0.37096383, -0.17949375,\n",
       "        0.01576688, -0.0892475 ,  0.00893679,  0.07159521,  0.08121706,\n",
       "        0.0090992 , -0.06418775,  0.05750302, -0.04087269, -0.01249581])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_train_pca[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
